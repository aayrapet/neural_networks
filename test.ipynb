{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38a1acbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/python/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from main import MLP_Classifier,Layer\n",
    "from sklearn.datasets import make_classification\n",
    "import optuna\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427a00a8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67427120",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "# Generate  dataset\n",
    "X, Y = make_classification(\n",
    "    n_samples=1000,     \n",
    "    n_features=4,       \n",
    "    n_redundant=0,      \n",
    "    n_clusters_per_class=1,\n",
    "    flip_y=0.1,         # Add label noise\n",
    "    class_sep=1.0,      # Class separation\n",
    "    n_classes=2,      # nb classes\n",
    ")\n",
    "\n",
    "\n",
    "noise = np.random.normal(0, 0.5, X.shape)\n",
    "X = X + noise\n",
    "X=pd.DataFrame(X)\n",
    "Y=pd.Series(Y)\n",
    "if len(np.unique(Y))==2:\n",
    "   Y=pd.DataFrame(Y)\n",
    "else: \n",
    "   Y=pd.get_dummies(Y).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e8c3c0",
   "metadata": {},
   "source": [
    "determine objective function to optimise :  minimise cross entropy (in pdf maximise log-likelihood).\n",
    "\n",
    "for example we optimise over batch size, learning rate and dropout (one of the most important parameters in NN).\n",
    "\n",
    "we could do also on layers but computantionally expensive for large datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15db729e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-02 16:31:40,679] Using an existing study with name 'MLP' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't forget to normalise input data and think about Batch normalisations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-02 16:31:41,905] Trial 2 finished with value: 0.39353641929822664 and parameters: {'batch_size': 687, 'alpha': 0.08443465052128196, 'dropout': 0.7595544399417837}. Best is trial 1 with value: 0.3868044002410619.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 757, 'alpha': 0.011780812577113267, 'dropout': 0.8375822042749481}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameter search space\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 500, 800)\n",
    "    alpha = trial.suggest_float(\"alpha\", 0.01, 0.1)\n",
    "    dropout_rate = trial.suggest_float(\"dropout\", 0.5, 0.9)\n",
    "\n",
    "    model = MLP_Classifier(\n",
    "        (\n",
    "            (\n",
    "                Layer(\n",
    "                    nb_neurons=20,\n",
    "                    activation_function=\"relu\",\n",
    "                    regul=(\"l2\", 0.1),\n",
    "                    initial=\"he\",\n",
    "                    batchnorm=True\n",
    "                ),\n",
    "                Layer(\n",
    "                    nb_neurons=10,\n",
    "                    activation_function=\"relu\",\n",
    "                    regul=(\"l2\", 0.1),\n",
    "                    initial=\"he\",\n",
    "                ),\n",
    "                Layer(\n",
    "                    nb_neurons=30,\n",
    "                    activation_function=\"relu\",\n",
    "                    regul=(\"dropout\", dropout_rate),\n",
    "                    initial=\"he\",\n",
    "                ),\n",
    "            )\n",
    "        ),\n",
    "        max_iter=2000,\n",
    "        thr=1e-5,\n",
    "        alpha=alpha,\n",
    "        seed=123,\n",
    "        batch_size=batch_size,\n",
    "        verbose=False,\n",
    "        optim=\"adam\"\n",
    "    )\n",
    "\n",
    "    model.train(X, Y)\n",
    "\n",
    "    score = model.loss(Y,model.y_hat)  # need to do on val set\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "storage = \"sqlite:///optuna_mlpsoftmax.db\"\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\", study_name=\"MLP\", storage=storage, load_if_exists=True\n",
    ")  # 'minimize' for loss functions\n",
    "study.optimize(objective, n_trials=1)\n",
    "\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a3077f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best value': [0.3868044002410619],\n",
       " 'params': {'batch_size': 757,\n",
       "  'alpha': 0.011780812577113267,\n",
       "  'dropout': 0.8375822042749481}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results={\"best value\" : study.best_trial.values,\"params\": study.best_trial.params}\n",
    "best_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d904ab",
   "metadata": {},
   "source": [
    "run model on optimised parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "662363f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "iteration 0 : TRAIN accuracy_score  : 0.7306666666666667, loss : 0.6721635938899835\n",
      "iteration 0 : TEST accuracy_score  : 0.768, loss : 0.6726893745359764\n",
      "-------------------------------------------------------------------------\n",
      "iteration 50 : TRAIN accuracy_score  : 0.7906666666666666, loss : 0.49132845994433305\n",
      "iteration 50 : TEST accuracy_score  : 0.828, loss : 0.4822462920750237\n",
      "-------------------------------------------------------------------------\n",
      "iteration 100 : TRAIN accuracy_score  : 0.8093333333333333, loss : 0.44333826703358514\n",
      "iteration 100 : TEST accuracy_score  : 0.84, loss : 0.4162559547337287\n",
      "-------------------------------------------------------------------------\n",
      "iteration 150 : TRAIN accuracy_score  : 0.8093333333333333, loss : 0.4243432461689899\n",
      "iteration 150 : TEST accuracy_score  : 0.848, loss : 0.3860931473604485\n",
      "-------------------------------------------------------------------------\n",
      "iteration 200 : TRAIN accuracy_score  : 0.82, loss : 0.4164224884520746\n",
      "iteration 200 : TEST accuracy_score  : 0.852, loss : 0.37956090080157456\n",
      "-------------------------------------------------------------------------\n",
      "iteration 250 : TRAIN accuracy_score  : 0.8266666666666667, loss : 0.4077746809449064\n",
      "iteration 250 : TEST accuracy_score  : 0.86, loss : 0.3761764830191581\n",
      "-------------------------------------------------------------------------\n",
      "iteration 300 : TRAIN accuracy_score  : 0.8253333333333334, loss : 0.4130810525307664\n",
      "iteration 300 : TEST accuracy_score  : 0.852, loss : 0.380830534215321\n",
      "-------------------------------------------------------------------------\n",
      "iteration 350 : TRAIN accuracy_score  : 0.8253333333333334, loss : 0.41560133559093226\n",
      "iteration 350 : TEST accuracy_score  : 0.856, loss : 0.3715387410558587\n",
      "-------------------------------------------------------------------------\n",
      "iteration 400 : TRAIN accuracy_score  : 0.8213333333333334, loss : 0.410392795499202\n",
      "iteration 400 : TEST accuracy_score  : 0.844, loss : 0.3749902548878826\n",
      "early stopping at epoch 428\n",
      "final accuracy_score 0.888\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "\n",
    "model = MLP_Classifier(\n",
    "    (\n",
    "        (\n",
    "            Layer(\n",
    "                nb_neurons=20,\n",
    "                activation_function=\"relu\",\n",
    "                regul=(\"l2\", 0.1),\n",
    "                initial=\"he\",\n",
    "                batchnorm=True\n",
    "         \n",
    "            ),\n",
    "            Layer(\n",
    "                nb_neurons=10,\n",
    "                activation_function=\"relu\",\n",
    "                regul=(\"l2\", 0.1),\n",
    "                initial=\"he\",\n",
    "                \n",
    "            ),\n",
    "            Layer(\n",
    "                nb_neurons=30,\n",
    "                activation_function=\"relu\",\n",
    "                regul=(\"dropout\", best_results[\"params\"][\"dropout\"]),\n",
    "                initial=\"he\",\n",
    "                \n",
    "            ),\n",
    "        )\n",
    "    ),\n",
    "    max_iter=2000,\n",
    "    thr=1e-5,\n",
    "    alpha=best_results[\"params\"][\"alpha\"],\n",
    "    seed=123,\n",
    "    batch_size=best_results[\"params\"][\"batch_size\"],\n",
    "    verbose=True,\n",
    "    optim=\"adam\",\n",
    "    nb_epochs_early_stopping=50\n",
    ")\n",
    "\n",
    "fct=accuracy_score\n",
    "\n",
    "model.train(X_train, y_train,X_test,y_test,fct)\n",
    "\n",
    "print(f\"final {fct.__name__}\", accuracy_score(model.predict(X_test), y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ea9d8ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'layer_type': layers.Layer,\n",
       "  'nb_neurons': 20,\n",
       "  'activ_fct': 'relu',\n",
       "  'regul': 'l2',\n",
       "  'regul_param': 0.1,\n",
       "  'init': 'he',\n",
       "  'law': 'normal',\n",
       "  'batchnorm': True},\n",
       " 2: {'layer_type': layers.Layer,\n",
       "  'nb_neurons': 10,\n",
       "  'activ_fct': 'relu',\n",
       "  'regul': 'l2',\n",
       "  'regul_param': 0.1,\n",
       "  'init': 'he',\n",
       "  'law': 'normal',\n",
       "  'batchnorm': False},\n",
       " 3: {'layer_type': layers.Layer,\n",
       "  'nb_neurons': 30,\n",
       "  'activ_fct': 'relu',\n",
       "  'regul': 'dropout',\n",
       "  'regul_param': 0.8375822042749481,\n",
       "  'init': 'he',\n",
       "  'law': 'normal',\n",
       "  'batchnorm': False}}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54dcee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import ConvLayer,MaxPoolLayer,Layer,FlatLayer\n",
    "from cnn import CNN\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d51f3f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't forget to normalise input data and think about Batch normalisations\n"
     ]
    }
   ],
   "source": [
    "\n",
    "q=CNN(\n",
    "\n",
    "    (\n",
    "        ConvLayer(in_channels=3,output_channels=16,kernel_size=2,stride=1,padding=True,activation_function=\"relu\",initial=\"lecun\",law=\"normal\"),\n",
    "        MaxPoolLayer(kernel_size=3,stride=2,padding=True),\n",
    "        ConvLayer(in_channels=16,output_channels=32,kernel_size=2,stride=1,padding=True,activation_function=\"relu\",initial=\"lecun\",law=\"normal\"),\n",
    "        MaxPoolLayer(kernel_size=3,stride=2,padding=True),\n",
    "        ConvLayer(in_channels=32,output_channels=64,kernel_size=2,stride=1,padding=True,activation_function=\"relu\",initial=\"lecun\",law=\"normal\"),\n",
    "        MaxPoolLayer(kernel_size=3,stride=2,padding=True),\n",
    "        FlatLayer(),\n",
    "        Layer(\n",
    "                nb_neurons=20,\n",
    "                activation_function=\"relu\",\n",
    "                regul=(\"l2\", 0.1),\n",
    "                initial=\"he\",\n",
    "                batchnorm=True\n",
    "         \n",
    "            ),\n",
    "            Layer(\n",
    "                nb_neurons=10,\n",
    "                activation_function=\"relu\",\n",
    "                regul=(\"l2\", 0.1),\n",
    "                initial=\"he\",\n",
    "                \n",
    "            ),\n",
    "            Layer(\n",
    "                nb_neurons=30,\n",
    "                activation_function=\"relu\",\n",
    "                regul=(\"dropout\",0.5),\n",
    "                initial=\"he\",\n",
    "                \n",
    "            ),\n",
    "        \n",
    "    ),\n",
    "    max_iter=2000,\n",
    "    thr=1e-5,\n",
    "    alpha=0.001,\n",
    "    seed=123,\n",
    "    batch_size=200,\n",
    "    verbose=True,\n",
    "    nb_epochs_early_stopping=20\n",
    "\n",
    "\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "532717c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7, 7, 3, 10)\n",
      "(7, 7, 16, 10)\n",
      "(4, 4, 16, 10)\n",
      "(4, 4, 32, 10)\n",
      "(2, 2, 32, 10)\n",
      "(2, 2, 64, 10)\n",
      "(1, 1, 64, 10)\n",
      "(1, 1, 64, 10)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10, 64)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np \n",
    "X=np.random.randn(7, 7, 3,10)\n",
    "\n",
    "q.train(X).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ab7ddd83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([1, 3, 5])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.ACV.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cb8acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.nb_cnn_layers+q.nb_layers#total\n",
    "\n",
    "from q.nb_cnn_layers+1 to total+1 do gradients mlp \n",
    "\n",
    "\n",
    "from 1 to q.nb_cnn_layers+1 do gradients cnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f804a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b558d2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 2, 2])\n",
      "(12, 64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conv = nn.Conv2d(in_channels=3,out_channels=16,kernel_size=2)\n",
    "print(conv.weight.shape)\n",
    "torch.Size([1, 1, 2, 2])\n",
    "\n",
    "print(nn.init._calculate_fan_in_and_fan_out(conv.weight))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19a998e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 144)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fanin=3*3*3\n",
    "FANOUT=3*3*16\n",
    "fanin,FANOUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28ede39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
