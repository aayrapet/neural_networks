{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "38a1acbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/python/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from main import MLP_Classifier,Layer\n",
    "from sklearn.datasets import make_classification\n",
    "import optuna\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427a00a8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "67427120",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "# Generate  dataset\n",
    "X, Y = make_classification(\n",
    "    n_samples=1000,     \n",
    "    n_features=4,       \n",
    "    n_redundant=0,      \n",
    "    n_clusters_per_class=1,\n",
    "    flip_y=0.1,         # Add label noise\n",
    "    class_sep=1.0,      # Class separation\n",
    "    n_classes=2,      # nb classes\n",
    ")\n",
    "\n",
    "\n",
    "noise = np.random.normal(0, 0.5, X.shape)\n",
    "X = X + noise\n",
    "X=pd.DataFrame(X)\n",
    "Y=pd.Series(Y)\n",
    "if len(np.unique(Y))==2:\n",
    "   Y=pd.DataFrame(Y)\n",
    "else: \n",
    "   Y=pd.get_dummies(Y).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e8c3c0",
   "metadata": {},
   "source": [
    "determine objective function to optimise :  minimise cross entropy (in pdf maximise log-likelihood).\n",
    "\n",
    "for example we optimise over batch size, learning rate and dropout (one of the most important parameters in NN).\n",
    "\n",
    "we could do also on layers but computantionally expensive for large datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "15db729e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2026-01-04 19:50:55,976] A new study created in RDB with name: MLP\n",
      "[I 2026-01-04 19:50:57,713] Trial 0 finished with value: 0.3785585541635659 and parameters: {'batch_size': 752, 'alpha': 0.02319128823729845, 'dropout': 0.5788575266859909}. Best is trial 0 with value: 0.3785585541635659.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 752, 'alpha': 0.02319128823729845, 'dropout': 0.5788575266859909}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameter search space\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 500, 800)\n",
    "    alpha = trial.suggest_float(\"alpha\", 0.01, 0.1)\n",
    "    dropout_rate = trial.suggest_float(\"dropout\", 0.5, 0.9)\n",
    "\n",
    "    model = MLP_Classifier(\n",
    "        (\n",
    "            (\n",
    "                Layer(\n",
    "                    nb_neurons=20,\n",
    "                    activation_function=\"relu\",\n",
    "                    regul=(\"l2\", 0.1),\n",
    "                    initial=\"he\",\n",
    "                    batchnorm=True\n",
    "                ),\n",
    "                Layer(\n",
    "                    nb_neurons=10,\n",
    "                    activation_function=\"relu\",\n",
    "                    regul=(\"l2\", 0.1),\n",
    "                    initial=\"he\",\n",
    "                ),\n",
    "                Layer(\n",
    "                    nb_neurons=30,\n",
    "                    activation_function=\"relu\",\n",
    "                    regul=(\"dropout\", dropout_rate),\n",
    "                    initial=\"he\",\n",
    "                ),\n",
    "            )\n",
    "        ),\n",
    "        max_iter=2000,\n",
    "        thr=1e-5,\n",
    "        alpha=alpha,\n",
    "        seed=123,\n",
    "        batch_size=batch_size,\n",
    "        verbose=False,\n",
    "        optim=\"adam\"\n",
    "    )\n",
    "\n",
    "    model.train(X, Y)\n",
    "\n",
    "    score = model.loss(Y,model.y_hat)  # need to do on val set\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "storage = \"sqlite:///optuna_mlpsoftmax.db\"\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\", study_name=\"MLP\", storage=storage, load_if_exists=True\n",
    ")  # 'minimize' for loss functions\n",
    "study.optimize(objective, n_trials=1)\n",
    "\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a3077f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best value': [0.3785585541635659],\n",
       " 'params': {'batch_size': 752,\n",
       "  'alpha': 0.02319128823729845,\n",
       "  'dropout': 0.5788575266859909}}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results={\"best value\" : study.best_trial.values,\"params\": study.best_trial.params}\n",
    "best_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d904ab",
   "metadata": {},
   "source": [
    "run model on optimised parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "662363f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "iteration 0 : TRAIN accuracy_score  : 0.7093333333333334, loss : 0.6566102261215156\n",
      "iteration 0 : TEST accuracy_score  : 0.748, loss : 0.6565915727919444\n",
      "-------------------------------------------------------------------------\n",
      "iteration 50 : TRAIN accuracy_score  : 0.8133333333333334, loss : 0.43423980488257347\n",
      "iteration 50 : TEST accuracy_score  : 0.828, loss : 0.41263360186056397\n",
      "-------------------------------------------------------------------------\n",
      "iteration 100 : TRAIN accuracy_score  : 0.8186666666666667, loss : 0.4144917150850996\n",
      "iteration 100 : TEST accuracy_score  : 0.852, loss : 0.39384797691126466\n",
      "-------------------------------------------------------------------------\n",
      "iteration 150 : TRAIN accuracy_score  : 0.8306666666666667, loss : 0.40984694893046175\n",
      "iteration 150 : TEST accuracy_score  : 0.86, loss : 0.3658694271920856\n",
      "early stopping at epoch 161\n",
      "final accuracy_score 0.888\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "\n",
    "model = MLP_Classifier(\n",
    "    (\n",
    "        (\n",
    "            Layer(\n",
    "                nb_neurons=20,\n",
    "                activation_function=\"relu\",\n",
    "                regul=(\"l2\", 0.1),\n",
    "                initial=\"he\",\n",
    "                batchnorm=True\n",
    "         \n",
    "            ),\n",
    "            Layer(\n",
    "                nb_neurons=10,\n",
    "                activation_function=\"relu\",\n",
    "                regul=(\"l2\", 0.1),\n",
    "                initial=\"he\",\n",
    "                \n",
    "            ),\n",
    "            Layer(\n",
    "                nb_neurons=30,\n",
    "                activation_function=\"relu\",\n",
    "                regul=(\"dropout\", best_results[\"params\"][\"dropout\"]),\n",
    "                initial=\"he\",\n",
    "                \n",
    "            ),\n",
    "        )\n",
    "    ),\n",
    "    max_iter=2000,\n",
    "    thr=1e-5,\n",
    "    alpha=best_results[\"params\"][\"alpha\"],\n",
    "    seed=123,\n",
    "    batch_size=best_results[\"params\"][\"batch_size\"],\n",
    "    verbose=True,\n",
    "    optim=\"adam\",\n",
    "    nb_epochs_early_stopping=50\n",
    ")\n",
    "\n",
    "fct=accuracy_score\n",
    "\n",
    "model.train(X_train, y_train,X_test,y_test,fct)\n",
    "\n",
    "print(f\"final {fct.__name__}\", accuracy_score(model.predict(X_test), y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "38ff193f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([3, 2, 1])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.E.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c35aaca5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.nb_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ea9d8ae4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: {'layer_type': layers.Layer,\n",
       "  'nb_neurons': 20,\n",
       "  'activ_fct': 'relu',\n",
       "  'regul': 'l2',\n",
       "  'regul_param': 0.1,\n",
       "  'init': 'he',\n",
       "  'law': 'normal',\n",
       "  'batchnorm': True},\n",
       " 2: {'layer_type': layers.Layer,\n",
       "  'nb_neurons': 10,\n",
       "  'activ_fct': 'relu',\n",
       "  'regul': 'l2',\n",
       "  'regul_param': 0.1,\n",
       "  'init': 'he',\n",
       "  'law': 'normal',\n",
       "  'batchnorm': False},\n",
       " 3: {'layer_type': layers.Layer,\n",
       "  'nb_neurons': 30,\n",
       "  'activ_fct': 'relu',\n",
       "  'regul': 'dropout',\n",
       "  'regul_param': 0.8375822042749481,\n",
       "  'init': 'he',\n",
       "  'law': 'normal',\n",
       "  'batchnorm': False}}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54dcee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import ConvLayer,MaxPoolLayer,Layer,FlatLayer\n",
    "from cnn import CNN\n",
    "import numpy as np "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d51f3f0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "q=CNN(\n",
    "\n",
    "    (\n",
    "        ConvLayer(in_channels=3,output_channels=16,kernel_size=2,stride=1,padding=True,activation_function=\"relu\",initial=\"lecun\",law=\"normal\"),\n",
    "        MaxPoolLayer(kernel_size=3,stride=2,padding=True),\n",
    "        ConvLayer(in_channels=16,output_channels=32,kernel_size=2,stride=1,padding=True,activation_function=\"relu\",initial=\"lecun\",law=\"normal\"),\n",
    "        MaxPoolLayer(kernel_size=3,stride=2,padding=True),\n",
    "        ConvLayer(in_channels=32,output_channels=64,kernel_size=2,stride=1,padding=True,activation_function=\"relu\",initial=\"lecun\",law=\"normal\"),\n",
    "        MaxPoolLayer(kernel_size=3,stride=2,padding=True),\n",
    "        \n",
    "        FlatLayer(),\n",
    "        Layer(\n",
    "                nb_neurons=20,\n",
    "                activation_function=\"relu\",\n",
    "                regul=(\"l2\", 0.1),\n",
    "                initial=\"he\",\n",
    "                batchnorm=True\n",
    "         \n",
    "            ),\n",
    "            Layer(\n",
    "                nb_neurons=10,\n",
    "                activation_function=\"relu\",\n",
    "                regul=(\"l2\", 0.1),\n",
    "                initial=\"he\",\n",
    "                \n",
    "            ),\n",
    "            Layer(\n",
    "                nb_neurons=30,\n",
    "                activation_function=\"relu\",\n",
    "                regul=(\"dropout\",0.5),\n",
    "                initial=\"he\",\n",
    "                \n",
    "            ),\n",
    "        \n",
    "    ),\n",
    "    max_iter=2000,\n",
    "    thr=1e-5,\n",
    "    alpha=0.001,\n",
    "    seed=123,\n",
    "    batch_size=200,\n",
    "    verbose=True,\n",
    "    nb_epochs_early_stopping=20\n",
    "\n",
    "\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9a01e585",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=np.random.randn(20, 20, 3,10)\n",
    "Y=np.random.choice([0, 1], size=(10,1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e19674fb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dummy res shape (1, 64)\n"
     ]
    }
   ],
   "source": [
    "q.train(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acf1ddf6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.nb_cnn_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "054838c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.nb_layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c46f9c6d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26e93d91",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.12667004, 3.89158695, 0.73909931, 0.92356768, 1.46190637,\n",
       "        2.86896681, 0.43592179, 0.44208886, 0.54217387, 0.        ,\n",
       "        1.09392343, 1.16337488, 0.        , 1.82052638, 0.        ,\n",
       "        2.15616352, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.40687296, 0.70889481, 0.        , 0.        , 0.        ,\n",
       "        0.93463105, 0.01786255, 0.73793597, 0.4328405 , 0.        ,\n",
       "        0.        , 1.11582354, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.76664667, 0.        , 0.        , 0.9349631 ,\n",
       "        0.28449726, 0.73353958, 0.83110961, 2.88449204, 0.        ,\n",
       "        0.20571789, 0.1875448 , 0.        , 0.89604675, 1.86586614,\n",
       "        0.        , 0.40452998, 0.        , 0.        , 0.62401816,\n",
       "        1.14414384, 0.        , 1.20756189, 0.05719768, 0.12704129,\n",
       "        0.6667232 , 0.73491228, 0.        , 1.64055764],\n",
       "       [0.        , 3.81690131, 0.70795512, 0.71252831, 1.34830024,\n",
       "        2.95381106, 0.        , 0.221113  , 0.59620179, 0.        ,\n",
       "        1.00229685, 0.90655881, 0.        , 1.70330474, 0.        ,\n",
       "        2.25596191, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.02558763, 0.60701523, 0.        , 0.31319615, 0.        ,\n",
       "        1.08389096, 0.39059226, 0.79717099, 0.42471229, 0.        ,\n",
       "        0.        , 0.98788213, 0.        , 0.        , 0.        ,\n",
       "        0.        , 1.00046533, 0.        , 0.        , 1.08257644,\n",
       "        0.26458417, 0.7712169 , 0.69974457, 2.87401621, 0.        ,\n",
       "        0.07539809, 0.32000544, 0.        , 0.79592615, 1.66962452,\n",
       "        0.        , 0.49901289, 0.23392768, 0.        , 0.60485231,\n",
       "        1.42543233, 0.        , 1.26120622, 0.        , 0.04306967,\n",
       "        0.71302621, 0.8823978 , 0.        , 2.27979081],\n",
       "       [0.32215997, 3.12659201, 0.55924829, 1.13209942, 1.75053051,\n",
       "        3.00232103, 0.02734333, 0.        , 0.37770795, 0.        ,\n",
       "        0.63636153, 0.38729921, 0.        , 1.45813021, 0.        ,\n",
       "        2.13198201, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.13855743, 0.60365523, 0.        , 0.        , 0.        ,\n",
       "        0.91443251, 0.24955558, 0.58053071, 0.81779513, 0.        ,\n",
       "        0.        , 1.08483444, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.61083533, 0.        , 0.        , 0.724675  ,\n",
       "        0.51903475, 0.80572265, 0.74823309, 2.96789033, 0.        ,\n",
       "        0.12832303, 0.        , 0.09668142, 0.28066352, 1.71685978,\n",
       "        0.        , 0.15537382, 0.10528428, 0.        , 0.26483818,\n",
       "        0.9721956 , 0.        , 1.62708582, 0.34369248, 0.        ,\n",
       "        0.31468774, 0.35411946, 0.09157234, 2.32040213],\n",
       "       [0.        , 3.47797441, 0.6255987 , 0.96571134, 1.45344489,\n",
       "        3.31711349, 0.24618136, 0.13374334, 0.80787302, 0.        ,\n",
       "        0.75781158, 0.71769985, 0.        , 1.9841893 , 0.        ,\n",
       "        2.13927605, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.24086936, 0.60351142, 0.        , 0.19312156, 0.        ,\n",
       "        0.51004876, 0.66817078, 0.60748982, 1.12749197, 0.        ,\n",
       "        0.        , 1.22592337, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.43297951, 0.        , 0.        , 0.88130095,\n",
       "        0.2778246 , 0.62232623, 0.73682785, 2.42172093, 0.        ,\n",
       "        0.97249508, 0.08238212, 0.02444542, 0.42066416, 1.95431246,\n",
       "        0.        , 0.60450922, 0.04654794, 0.        , 0.97013469,\n",
       "        1.83760202, 0.        , 1.4574241 , 0.        , 0.        ,\n",
       "        0.20019039, 0.56395142, 0.        , 2.58766351],\n",
       "       [0.13980377, 3.38239006, 0.59264915, 0.63747921, 1.66998686,\n",
       "        3.01301816, 0.59774329, 0.27610115, 0.3061914 , 0.        ,\n",
       "        1.19829647, 0.87694522, 0.        , 1.8145062 , 0.        ,\n",
       "        2.00663284, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.27013721, 0.42973229, 0.        , 0.        , 0.        ,\n",
       "        0.72977808, 0.74830846, 0.86715122, 0.70592934, 0.        ,\n",
       "        0.        , 1.19396103, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.52028469, 0.        , 0.        , 0.61979556,\n",
       "        0.15345292, 0.99761002, 0.49678481, 3.05240309, 0.        ,\n",
       "        0.33320279, 0.19871872, 0.        , 0.91830618, 2.12060327,\n",
       "        0.19734288, 0.        , 0.        , 0.        , 0.77077297,\n",
       "        1.17224219, 0.        , 1.51851297, 0.05118721, 0.47648688,\n",
       "        0.23082951, 0.44692462, 0.        , 2.36537352],\n",
       "       [0.16974016, 3.20506135, 0.48558606, 0.79227927, 1.39461927,\n",
       "        3.03468319, 0.        , 0.21317275, 0.23692144, 0.        ,\n",
       "        1.1281131 , 0.8468122 , 0.        , 1.59430307, 0.        ,\n",
       "        2.29914174, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.21131339, 0.30448326, 0.        , 0.17572392, 0.        ,\n",
       "        0.76169001, 0.22639202, 0.61240036, 0.31674448, 0.        ,\n",
       "        0.        , 0.78644505, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.64498128, 0.        , 0.        , 0.2729312 ,\n",
       "        0.0841938 , 0.9246318 , 0.55802943, 2.71554701, 0.        ,\n",
       "        0.25278893, 0.05857244, 0.        , 1.31107864, 1.57246482,\n",
       "        0.        , 0.04269768, 0.        , 0.        , 0.2930965 ,\n",
       "        0.76284593, 0.        , 0.94616138, 0.04588222, 0.41594797,\n",
       "        0.17227403, 0.59968836, 0.        , 2.00478661],\n",
       "       [0.        , 3.24083179, 0.41550299, 0.32472927, 1.40986016,\n",
       "        2.88789859, 0.14730069, 0.02200007, 0.30863866, 0.        ,\n",
       "        0.84221369, 0.81333145, 0.        , 1.72127251, 0.        ,\n",
       "        2.04038341, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.3903349 , 0.42319558, 0.        , 0.03430845, 0.        ,\n",
       "        1.07025446, 0.51506354, 0.53556034, 0.16666236, 0.        ,\n",
       "        0.        , 0.7531894 , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.55643883, 0.        , 0.        , 0.45666884,\n",
       "        0.        , 0.69607291, 0.60124185, 3.00618703, 0.        ,\n",
       "        0.20510962, 0.0458069 , 0.        , 0.86809613, 1.79756888,\n",
       "        0.04077716, 0.47234842, 0.        , 0.        , 0.58372376,\n",
       "        1.01983326, 0.        , 1.12346127, 0.        , 0.        ,\n",
       "        0.35534046, 0.92217533, 0.        , 2.26700405],\n",
       "       [0.        , 4.18135602, 0.80326401, 1.11636623, 1.77776851,\n",
       "        3.23050789, 0.19831491, 0.22508843, 0.49570272, 0.        ,\n",
       "        0.68895759, 0.71959753, 0.        , 1.69699663, 0.        ,\n",
       "        2.55530011, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.59658369, 0.7918295 , 0.        , 0.        , 0.        ,\n",
       "        0.57645661, 0.62233126, 0.84386009, 0.89173849, 0.        ,\n",
       "        0.        , 1.16046547, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.5370135 , 0.        , 0.        , 0.48784605,\n",
       "        0.31773986, 0.80044227, 0.93741873, 3.7213028 , 0.        ,\n",
       "        0.32733178, 0.        , 0.        , 0.74015506, 1.68163725,\n",
       "        0.        , 0.18694335, 0.03766842, 0.        , 0.76679361,\n",
       "        1.02465776, 0.        , 1.30612057, 0.        , 0.        ,\n",
       "        0.54065407, 0.43764238, 0.06647492, 2.35953505],\n",
       "       [0.        , 3.18820076, 0.46890384, 0.85889504, 2.07395709,\n",
       "        2.74595893, 0.25985422, 0.        , 0.58967814, 0.        ,\n",
       "        1.18384583, 0.52530652, 0.        , 2.1438427 , 0.        ,\n",
       "        2.5120239 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.11570069, 0.70935576, 0.        , 0.23955213, 0.        ,\n",
       "        0.58751437, 0.28871852, 0.36005689, 0.93168257, 0.        ,\n",
       "        0.        , 1.35141345, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.3936402 , 0.        , 0.        , 0.5728484 ,\n",
       "        0.37020397, 1.26998211, 0.63249744, 2.84761601, 0.        ,\n",
       "        0.        , 0.        , 0.11617887, 0.68417159, 1.93835474,\n",
       "        0.        , 0.38537228, 0.23085723, 0.        , 0.58805824,\n",
       "        1.3664268 , 0.        , 1.62649088, 0.        , 0.        ,\n",
       "        0.18074514, 0.27679663, 0.        , 2.95893582],\n",
       "       [0.12966213, 3.66611164, 0.90686274, 0.38513791, 1.61001929,\n",
       "        2.56467199, 0.20629819, 0.20186724, 0.31309519, 0.        ,\n",
       "        0.83047073, 0.72581696, 0.        , 1.68801248, 0.        ,\n",
       "        2.1281921 , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.45793425, 0.52501703, 0.        , 0.21267178, 0.        ,\n",
       "        0.62650511, 0.61860505, 0.90570287, 0.41315914, 0.        ,\n",
       "        0.        , 1.25646369, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.60229557, 0.        , 0.        , 0.58063798,\n",
       "        0.01163165, 0.59991976, 0.75235667, 3.10262962, 0.        ,\n",
       "        0.17629982, 0.62423976, 0.07768482, 0.72861206, 1.78934432,\n",
       "        0.        , 0.26010404, 0.06368073, 0.        , 0.65728299,\n",
       "        1.68050245, 0.        , 1.41611312, 0.        , 0.        ,\n",
       "        0.37088549, 0.2835579 , 0.        , 2.22728404]])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.forward_cnn(X,\"train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "78bb3eca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7 FlatLayer\n",
      "6 MaxPoolLayer\n",
      "5 ConvLayer\n",
      "4 MaxPoolLayer\n",
      "3 ConvLayer\n",
      "2 MaxPoolLayer\n",
      "1 ConvLayer\n"
     ]
    }
   ],
   "source": [
    "q.test(X,Y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
