{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "38a1acbf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/python/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from main import MLP_Classifier,Layer\n",
    "from sklearn.datasets import make_classification\n",
    "import optuna\n",
    "from sklearn.metrics import accuracy_score,precision_score,recall_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427a00a8",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "67427120",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "# Generate  dataset\n",
    "X, Y = make_classification(\n",
    "    n_samples=1000,     \n",
    "    n_features=4,       \n",
    "    n_redundant=0,      \n",
    "    n_clusters_per_class=1,\n",
    "    flip_y=0.1,         # Add label noise\n",
    "    class_sep=1.0,      # Class separation\n",
    "    n_classes=2,      # nb classes\n",
    ")\n",
    "\n",
    "\n",
    "noise = np.random.normal(0, 0.5, X.shape)\n",
    "X = X + noise\n",
    "X=pd.DataFrame(X)\n",
    "Y=pd.Series(Y)\n",
    "if len(np.unique(Y))==2:\n",
    "   Y=pd.DataFrame(Y)\n",
    "else: \n",
    "   Y=pd.get_dummies(Y).astype(int)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5e8c3c0",
   "metadata": {},
   "source": [
    "determine objective function to optimise :  minimise cross entropy (in pdf maximise log-likelihood).\n",
    "\n",
    "for example we optimise over batch size, learning rate and dropout (one of the most important parameters in NN).\n",
    "\n",
    "we could do also on layers but computantionally expensive for large datasets.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "15db729e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-26 14:46:36,265] Using an existing study with name 'MLP' instead of creating a new one.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't forget to normalise input data and think about Batch normalisations\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[I 2025-10-26 14:46:37,364] Trial 15 finished with value: 0.37788340705543 and parameters: {'batch_size': 700, 'alpha': 0.08220049763763941, 'dropout': 0.746047498058809}. Best is trial 15 with value: 0.37788340705543.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Hyperparameters: {'batch_size': 700, 'alpha': 0.08220049763763941, 'dropout': 0.746047498058809}\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def objective(trial):\n",
    "    # Define hyperparameter search space\n",
    "    batch_size = trial.suggest_int(\"batch_size\", 500, 800)\n",
    "    alpha = trial.suggest_float(\"alpha\", 0.01, 0.1)\n",
    "    dropout_rate = trial.suggest_float(\"dropout\", 0.5, 0.9)\n",
    "\n",
    "    model = MLP_Classifier(\n",
    "        (\n",
    "            (\n",
    "                Layer(\n",
    "                    nb_neurons=20,\n",
    "                    activation_function=\"relu\",\n",
    "                    regul=(\"l2\", 0.1),\n",
    "                    initial=\"he\",\n",
    "                    batchnorm=True\n",
    "                ),\n",
    "                Layer(\n",
    "                    nb_neurons=10,\n",
    "                    activation_function=\"relu\",\n",
    "                    regul=(\"l2\", 0.1),\n",
    "                    initial=\"he\",\n",
    "                ),\n",
    "                Layer(\n",
    "                    nb_neurons=30,\n",
    "                    activation_function=\"relu\",\n",
    "                    regul=(\"dropout\", dropout_rate),\n",
    "                    initial=\"he\",\n",
    "                ),\n",
    "            )\n",
    "        ),\n",
    "        max_iter=2000,\n",
    "        thr=1e-5,\n",
    "        alpha=alpha,\n",
    "        seed=123,\n",
    "        batch_size=batch_size,\n",
    "        verbose=False,\n",
    "        optim=\"adam\"\n",
    "    )\n",
    "\n",
    "    model.train(X, Y)\n",
    "\n",
    "    score = model.loss(Y,model.y_hat)  # need to do on val set\n",
    "\n",
    "    return score\n",
    "\n",
    "\n",
    "storage = \"sqlite:///optuna_mlpsoftmax.db\"\n",
    "study = optuna.create_study(\n",
    "    direction=\"minimize\", study_name=\"MLP\", storage=storage, load_if_exists=True\n",
    ")  # 'minimize' for loss functions\n",
    "study.optimize(objective, n_trials=1)\n",
    "\n",
    "print(\"Best Hyperparameters:\", study.best_params)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a3077f4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'best value': [0.37788340705543],\n",
       " 'params': {'batch_size': 700,\n",
       "  'alpha': 0.08220049763763941,\n",
       "  'dropout': 0.746047498058809}}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results={\"best value\" : study.best_trial.values,\"params\": study.best_trial.params}\n",
    "best_results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a5d904ab",
   "metadata": {},
   "source": [
    "run model on optimised parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "662363f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-------------------------------------------------------------------------\n",
      "iteration 0 : TRAIN accuracy_score  : 0.748, loss : 0.5357972415572081\n",
      "iteration 0 : TEST accuracy_score  : 0.716, loss : 0.5455762295857955\n",
      "-------------------------------------------------------------------------\n",
      "iteration 50 : TRAIN accuracy_score  : 0.8293333333333334, loss : 0.3997065067777386\n",
      "iteration 50 : TEST accuracy_score  : 0.864, loss : 0.3534494506856128\n",
      "early stopping at epoch 79\n",
      "final accuracy_score 0.864\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.25, random_state=42)\n",
    "\n",
    "model = MLP_Classifier(\n",
    "    (\n",
    "        (\n",
    "            Layer(\n",
    "                nb_neurons=20,\n",
    "                activation_function=\"relu\",\n",
    "                regul=(\"l2\", 0.1),\n",
    "                initial=\"he\",\n",
    "                batchnorm=True\n",
    "         \n",
    "            ),\n",
    "            Layer(\n",
    "                nb_neurons=10,\n",
    "                activation_function=\"relu\",\n",
    "                regul=(\"l2\", 0.1),\n",
    "                initial=\"he\",\n",
    "                \n",
    "            ),\n",
    "            Layer(\n",
    "                nb_neurons=30,\n",
    "                activation_function=\"relu\",\n",
    "                regul=(\"dropout\", best_results[\"params\"][\"dropout\"]),\n",
    "                initial=\"he\",\n",
    "                \n",
    "            ),\n",
    "        )\n",
    "    ),\n",
    "    max_iter=2000,\n",
    "    thr=1e-5,\n",
    "    alpha=best_results[\"params\"][\"alpha\"],\n",
    "    seed=123,\n",
    "    batch_size=best_results[\"params\"][\"batch_size\"],\n",
    "    verbose=True,\n",
    "    optim=\"adam\",\n",
    "    nb_epochs_early_stopping=50\n",
    ")\n",
    "\n",
    "fct=accuracy_score\n",
    "\n",
    "model.train(X_train, y_train,X_test,y_test,fct)\n",
    "\n",
    "print(f\"final {fct.__name__}\", accuracy_score(model.predict(X_test), y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54dcee5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from layers import ConvLayer,MaxPoolLayer,Layer,FlatLayer\n",
    "from cnn import CNN\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d51f3f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Don't forget to normalise input data and think about Batch normalisations\n"
     ]
    }
   ],
   "source": [
    "\n",
    "q=CNN(\n",
    "\n",
    "    (\n",
    "        ConvLayer(in_channels=3,output_channels=16,kernel_size=2,stride=1,padding=True,activation_function=\"relu\",regul=None,initial=\"lecun\",law=\"normal\",batchnorm=False),\n",
    "        MaxPoolLayer(kernel_size=3,stride=2,padding=True),\n",
    "        ConvLayer(in_channels=16,output_channels=32,kernel_size=2,stride=1,padding=True,activation_function=\"relu\",regul=None,initial=\"lecun\",law=\"normal\",batchnorm=False),\n",
    "        MaxPoolLayer(kernel_size=3,stride=2,padding=True),\n",
    "        ConvLayer(in_channels=32,output_channels=64,kernel_size=2,stride=1,padding=True,activation_function=\"relu\",regul=None,initial=\"lecun\",law=\"normal\",batchnorm=False),\n",
    "        MaxPoolLayer(kernel_size=3,stride=2,padding=True),\n",
    "        FlatLayer(),\n",
    "        Layer(\n",
    "                nb_neurons=20,\n",
    "                activation_function=\"relu\",\n",
    "                regul=(\"l2\", 0.1),\n",
    "                initial=\"he\",\n",
    "                batchnorm=True\n",
    "         \n",
    "            ),\n",
    "            Layer(\n",
    "                nb_neurons=10,\n",
    "                activation_function=\"relu\",\n",
    "                regul=(\"l2\", 0.1),\n",
    "                initial=\"he\",\n",
    "                \n",
    "            ),\n",
    "            Layer(\n",
    "                nb_neurons=30,\n",
    "                activation_function=\"relu\",\n",
    "                regul=(\"dropout\",0.5),\n",
    "                initial=\"he\",\n",
    "                \n",
    "            ),\n",
    "        \n",
    "    )\n",
    "\n",
    "\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dfcb9c7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "q.conv_kernel={}\n",
    "q.conv_bias={}\n",
    "q.kernels_init()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19d67373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.1225, -0.2641],\n",
       "          [-0.0340, -0.0439]],\n",
       "\n",
       "         [[ 0.1394, -0.0772],\n",
       "          [-0.2839, -0.1727]],\n",
       "\n",
       "         [[ 0.1465, -0.0546],\n",
       "          [-0.0507,  0.0886]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.2322,  0.2665],\n",
       "          [-0.0632, -0.0999]],\n",
       "\n",
       "         [[-0.1368, -0.1275],\n",
       "          [-0.0675,  0.1515]],\n",
       "\n",
       "         [[-0.1079,  0.1667],\n",
       "          [ 0.0096, -0.0065]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0298,  0.0176],\n",
       "          [-0.1669, -0.3668]],\n",
       "\n",
       "         [[ 0.0143, -0.1509],\n",
       "          [-0.0376,  0.0178]],\n",
       "\n",
       "         [[-0.1628, -0.0615],\n",
       "          [-0.2679,  0.1186]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0038, -0.0112],\n",
       "          [-0.0246, -0.1214]],\n",
       "\n",
       "         [[ 0.1126, -0.0315],\n",
       "          [ 0.1334, -0.0373]],\n",
       "\n",
       "         [[ 0.1070,  0.2012],\n",
       "          [-0.1487,  0.1460]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0410, -0.1041],\n",
       "          [-0.2022,  0.0283]],\n",
       "\n",
       "         [[-0.0548,  0.0408],\n",
       "          [-0.1973, -0.1749]],\n",
       "\n",
       "         [[ 0.0681, -0.0104],\n",
       "          [-0.1469,  0.2228]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0177,  0.0462],\n",
       "          [-0.0022, -0.1197]],\n",
       "\n",
       "         [[-0.1021, -0.0358],\n",
       "          [ 0.0543, -0.0168]],\n",
       "\n",
       "         [[-0.2683, -0.2248],\n",
       "          [-0.0853, -0.0649]]],\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "        [[[-0.0684,  0.0238],\n",
       "          [-0.1269,  0.0960]],\n",
       "\n",
       "         [[ 0.0534, -0.0321],\n",
       "          [-0.1666,  0.0689]],\n",
       "\n",
       "         [[ 0.1361,  0.0089],\n",
       "          [-0.0991, -0.1612]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.1397, -0.1065],\n",
       "          [-0.0141, -0.1188]],\n",
       "\n",
       "         [[ 0.0594, -0.0262],\n",
       "          [ 0.1398, -0.1026]],\n",
       "\n",
       "         [[-0.1357,  0.1102],\n",
       "          [ 0.0279, -0.1669]]],\n",
       "\n",
       "\n",
       "        [[[ 0.0848, -0.2063],\n",
       "          [-0.0644, -0.2002]],\n",
       "\n",
       "         [[-0.0312,  0.0596],\n",
       "          [ 0.0814, -0.0222]],\n",
       "\n",
       "         [[-0.1389,  0.1265],\n",
       "          [-0.0079, -0.3236]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-0.0377,  0.0765],\n",
       "          [ 0.0111,  0.0076]],\n",
       "\n",
       "         [[-0.0707,  0.0587],\n",
       "          [ 0.0420,  0.0185]],\n",
       "\n",
       "         [[-0.0534, -0.0890],\n",
       "          [-0.0338,  0.0012]]],\n",
       "\n",
       "\n",
       "        [[[ 0.1691,  0.0300],\n",
       "          [-0.0060, -0.1308]],\n",
       "\n",
       "         [[ 0.0135,  0.1426],\n",
       "          [-0.1090, -0.0180]],\n",
       "\n",
       "         [[ 0.0533, -0.0061],\n",
       "          [ 0.2527, -0.1937]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[ 0.0702,  0.0206],\n",
       "          [ 0.0674, -0.1736]],\n",
       "\n",
       "         [[ 0.0437,  0.1113],\n",
       "          [-0.1234,  0.0934]],\n",
       "\n",
       "         [[ 0.0812, -0.2614],\n",
       "          [ 0.1112, -0.2899]]]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.conv_kernel[3 ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "13f8d716",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ConvLayer'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.network[1][\"layer_type\"].__name__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "83225436",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[[-3.05320347e-01,  2.73165973e-02],\n",
       "         [ 1.75627046e-02, -8.15219774e-02]],\n",
       "\n",
       "        [[-2.62418893e-01, -1.17711239e-01],\n",
       "         [ 2.54002437e-02, -3.72959268e-01]],\n",
       "\n",
       "        [[-3.07543311e-01, -3.90278487e-01],\n",
       "         [-2.28766389e-01,  7.96790175e-02]]],\n",
       "\n",
       "\n",
       "       [[[-2.20186808e-01, -2.01998420e-01],\n",
       "         [ 5.18998067e-01,  1.44602622e-01]],\n",
       "\n",
       "        [[ 3.42836532e-01, -2.49860842e-01],\n",
       "         [ 1.91245650e-01,  1.96779655e-01]],\n",
       "\n",
       "        [[-3.48306552e-02, -1.49213731e-01],\n",
       "         [-7.24786023e-02,  1.38582444e-01]]],\n",
       "\n",
       "\n",
       "       [[[-5.36575490e-01, -3.85727115e-02],\n",
       "         [-3.71185928e-01, -4.10202974e-01]],\n",
       "\n",
       "        [[-2.87387085e-01, -6.39429425e-01],\n",
       "         [-3.61344098e-02, -1.22941042e-03]],\n",
       "\n",
       "        [[-1.03917460e-01,  1.94367237e-01],\n",
       "         [ 2.19478507e-01,  1.55339075e-01]]],\n",
       "\n",
       "\n",
       "       [[[ 3.69886620e-01, -2.72440569e-01],\n",
       "         [-1.07244907e-01,  4.38595579e-01]],\n",
       "\n",
       "        [[-1.42125179e-02,  5.79476579e-01],\n",
       "         [ 1.84028196e-01, -2.96855321e-01]],\n",
       "\n",
       "        [[-2.40845986e-01, -5.15876027e-02],\n",
       "         [-2.37836974e-01,  4.53470815e-01]]],\n",
       "\n",
       "\n",
       "       [[[ 3.02181240e-01,  4.56101663e-01],\n",
       "         [ 2.62515263e-01,  1.84299135e-02]],\n",
       "\n",
       "        [[-1.71345067e-01,  3.12007727e-01],\n",
       "         [-2.12709625e-01, -1.59677643e-01]],\n",
       "\n",
       "        [[-2.35327880e-01, -1.71582420e-01],\n",
       "         [-2.76670137e-01, -3.22519903e-01]]],\n",
       "\n",
       "\n",
       "       [[[ 8.30705178e-01, -9.25367113e-02],\n",
       "         [ 3.26815131e-01, -3.04160997e-02]],\n",
       "\n",
       "        [[-3.17068019e-01,  2.16220808e-01],\n",
       "         [-1.03388149e+00, -4.92330447e-01]],\n",
       "\n",
       "        [[-8.37712409e-01, -3.29483936e-02],\n",
       "         [ 2.16715605e-01,  3.29085232e-01]]],\n",
       "\n",
       "\n",
       "       [[[ 3.09026862e-01,  1.70448630e-01],\n",
       "         [ 1.04718101e-01, -9.48279566e-02]],\n",
       "\n",
       "        [[ 9.13439534e-02,  8.71181081e-02],\n",
       "         [-2.44978981e-01,  2.78506365e-01]],\n",
       "\n",
       "        [[ 4.60598932e-01, -4.91282123e-01],\n",
       "         [-6.79216445e-01, -1.22073760e-01]]],\n",
       "\n",
       "\n",
       "       [[[-1.78979264e-01, -1.98162228e-01],\n",
       "         [ 4.13805051e-01,  1.65947720e-02]],\n",
       "\n",
       "        [[-3.68326135e-01, -1.65892909e-01],\n",
       "         [ 1.79523934e-01,  4.74163453e-01]],\n",
       "\n",
       "        [[-2.97663109e-01,  3.62196558e-02],\n",
       "         [ 6.11548355e-02, -9.16229845e-02]]],\n",
       "\n",
       "\n",
       "       [[[ 4.04329361e-01,  4.22860901e-02],\n",
       "         [ 4.34063267e-01,  4.00850998e-03]],\n",
       "\n",
       "        [[ 3.45973602e-01, -1.56699218e-01],\n",
       "         [ 7.81246121e-02, -8.18587410e-03]],\n",
       "\n",
       "        [[-1.92667487e-03,  2.09026374e-01],\n",
       "         [-9.26308684e-03, -4.08563503e-01]]],\n",
       "\n",
       "\n",
       "       [[[ 3.15663548e-01,  5.00713155e-01],\n",
       "         [-1.88046585e-01,  1.41550200e-01]],\n",
       "\n",
       "        [[ 4.01290100e-02, -8.78243993e-02],\n",
       "         [ 1.78455195e-01,  8.51090416e-04]],\n",
       "\n",
       "        [[ 4.03281007e-01,  9.30318728e-02],\n",
       "         [-5.40014411e-02, -4.21744094e-01]]],\n",
       "\n",
       "\n",
       "       [[[-4.50912814e-01,  2.85582519e-02],\n",
       "         [-3.61840624e-01,  2.46566542e-01]],\n",
       "\n",
       "        [[-1.65472045e-01,  2.39872005e-01],\n",
       "         [ 4.50235437e-01,  4.47253623e-01]],\n",
       "\n",
       "        [[-1.26893113e-02,  6.92156591e-02],\n",
       "         [ 4.84535093e-01,  4.33244451e-01]]],\n",
       "\n",
       "\n",
       "       [[[-3.17802450e-02, -1.15959085e-02],\n",
       "         [-2.20698976e-01,  3.45087258e-01]],\n",
       "\n",
       "        [[-2.52603890e-01,  3.62955709e-01],\n",
       "         [ 4.78374964e-01, -8.83611173e-03]],\n",
       "\n",
       "        [[-4.32017349e-01,  1.91472654e-01],\n",
       "         [ 2.12320774e-02,  4.43141731e-01]]],\n",
       "\n",
       "\n",
       "       [[[-3.62434752e-02,  3.04777547e-02],\n",
       "         [-2.48175385e-01,  1.44517332e-01]],\n",
       "\n",
       "        [[-3.11170404e-01,  3.27635516e-01],\n",
       "         [ 2.44384312e-01,  3.09704524e-01]],\n",
       "\n",
       "        [[ 1.19435456e-01,  5.14771859e-01],\n",
       "         [ 6.49498336e-02,  5.40396435e-02]]],\n",
       "\n",
       "\n",
       "       [[[ 9.00639332e-02,  4.95233111e-01],\n",
       "         [ 2.56594500e-01,  2.24200900e-01]],\n",
       "\n",
       "        [[-2.93617004e-01, -4.16490991e-01],\n",
       "         [-3.37099693e-01,  2.73815614e-02]],\n",
       "\n",
       "        [[ 7.87684461e-02,  1.51802699e-01],\n",
       "         [ 8.23019444e-02, -5.30996764e-01]]],\n",
       "\n",
       "\n",
       "       [[[ 7.25012149e-02,  2.44165025e-01],\n",
       "         [ 1.54017250e-01, -3.15695525e-01]],\n",
       "\n",
       "        [[-1.39920016e-01, -3.48266229e-01],\n",
       "         [ 5.87812620e-01, -3.24017448e-01]],\n",
       "\n",
       "        [[-4.36442079e-01, -3.69253085e-01],\n",
       "         [ 1.47988227e-01,  1.12989296e-01]]],\n",
       "\n",
       "\n",
       "       [[[-6.95160302e-01,  1.28550558e-01],\n",
       "         [-1.85746539e-01, -3.47030641e-01]],\n",
       "\n",
       "        [[-1.38555751e-01, -1.73297069e-01],\n",
       "         [ 1.96930420e-01, -1.82548052e-01]],\n",
       "\n",
       "        [[-4.96887467e-02,  1.35540830e-01],\n",
       "         [ 4.56527834e-01, -4.29917478e-01]]]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "#in mlp netwrok:\n",
    "fan_in=2\n",
    "fan_out=3\n",
    "\n",
    "np.random.normal(0, np.sqrt(1 / fan_in), (fan_in, fan_out))\n",
    "\n",
    "#in cnn let kernel be shape (16,3,2,2)\n",
    "fan_in=2*2*3\n",
    "fan_out=2*2*16\n",
    "\n",
    "np.random.normal(0, np.sqrt(1 / fan_in), (16, 3,2,2))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05cb8acc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "8"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "q.nb_cnn_layers+q.nb_layers#total\n",
    "\n",
    "from q.nb_cnn_layers+1 to total+1 do gradients mlp \n",
    "\n",
    "\n",
    "from 1 to q.nb_cnn_layers+1 do gradients cnn "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7f804a1f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "b558d2fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 2, 2])\n",
      "(12, 64)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "conv = nn.Conv2d(in_channels=3,out_channels=16,kernel_size=2)\n",
    "print(conv.weight.shape)\n",
    "torch.Size([1, 1, 2, 2])\n",
    "\n",
    "print(nn.init._calculate_fan_in_and_fan_out(conv.weight))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "19a998e7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27, 144)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fanin=3*3*3\n",
    "FANOUT=3*3*16\n",
    "fanin,FANOUT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "28ede39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
