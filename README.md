# ğŸ§  NN-from-Scratch

*A journey into building a deep learning library from the ground up.*

---

## ğŸš€ Motivation

Instead of importing `sklearn.neural_network.MLPClassifier` or TensorFlowâ€™s `Dense` layer, this project is about **reinventing the wheel â€” on purpose**.  

The best way to truly understand:

- **Forward propagation**
- **Backpropagation**
- **Weight initialization**
- **Regularization**
- **Optimizers**
- **Batch_norm**

â€¦is to code them by hand.

This repo is my sandbox for building and experimenting with a **Multi-Layer Perceptron (MLP)** from scratch. Other models TBD


The link to theoretical pdf: https://www.overleaf.com/read/pmbzgsrrdxws#08d781

---

## ğŸ› ï¸ Features (so far)

- âœ… Custom `Layer` class to define architecture
- âœ… Strong parameter validation with friendly error messages
- âœ… Activation functions: **Sigmoid**, **ReLU**, **Tanh**
- âœ… Initializations: **Random**, **Xavier**, **He**, **LeCun**
- âœ… Additional optimizers: **SGD**, **Mini-batch GD**, **Adam**
- âœ… Loss functions: **Binary Cross-Entropy**, **Multi-class Cross-Entropy**
- âœ… Regularization: **L2**, **Dropout**
- âœ… Training loop with convergence check and early stopping.
- âœ… Batch-normalisation 


---

## ğŸ”® Roadmap (coming soon)

- â³ CNN


---

## ğŸ“– Philosophy

This project isnâ€™t about outperforming PyTorch or TensorFlow.  
Itâ€™s about **education**: exposing the internals of an MLP and exploring each design choice along the way.  

Think of it as building your own "mini-Keras" to really **feel the math** behind deep learning.

---

## â–¶ï¸ Quick Example

```python
import pandas as pd
from main import Layer, MLP_Classifier

# Define architecture
layers = (
    Layer(8, "tanh", regul=("dropout", 0.5), initial="xavier",batchnorm=True),
    Layer(4, "relu", regul=("l2", 0.9), initial="he",),
    Layer(100, "relu", initial="he",law="uniform"),
)

# Instantiate model
mlp = MLP_Classifier(layers, alpha=0.01, max_iter=1000, seed=42, optim="adam", batch_size=100, nb_epochs_early_stopping=50)

# Train (X, Y must be pandas DataFrames)
mlp.train(X_train, Y_train)

#or with test set just to see validation data set performance during training
mlp.train(X_train, Y_train,X_test,Y_test)
# Predict
preds = mlp.predict(X_test)

